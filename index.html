<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--    <div class="navbar-brand">-->
<!--        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--            <span aria-hidden="true"></span>-->
<!--            <span aria-hidden="true"></span>-->
<!--            <span aria-hidden="true"></span>-->
<!--        </a>-->
<!--    </div>-->
<!--</nav>-->

<section class="hero" id="video-background">
    <video autoplay muted loop id="background-video">
        <source src="static/videos/out_cut.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered text-frame">
                    <h1 class="title is-1 publication-title">FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning</h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            <span><a href="https://jiahenghu.github.io/">Jiaheng Hu</a><sup>1,2</sup>, </span>
                            <span><a href="https://rosehendrix.com/">Rose Hendrix</a><sup>1</sup>, </span>
                            <span><a href="https://homes.cs.washington.edu/~ali/">Ali Farhadi</a><sup>1,3</sup>, </span>
                            <span><a href="https://anikem.github.io/">Aniruddha Kembhavi</a><sup>1,3</sup>, </span>
                            <br>
                            <span><a href="https://robertomartinmartin.com/">Roberto Martín-Martín</a><sup>2</sup>, </span>
                            <span><a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a><sup>2,4</sup>, </span>
                            <span><a href="https://kuohaozeng.github.io/">Kuo-Hao Zeng</a><sup>1,†</sup>, </span>
                            <span><a href="https://ehsanik.github.io/Home.html">Kiana Ehsani</a><sup>1,†</sup> </span>
                        </span>
                    </div>
                      <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>†</sup>Equal Supervision</span>
                        <br>
                        <span class="author-block"><sup>1</sup>Allen Institute for AI,</span>
                        <span class="author-block"><sup>2</sup>University of Texas at Austin,</span>
                        <span class="author-block"><sup>3</sup>University of Washington,</span>
                        <span class="author-block"><sup>4</sup>Sony AI,</span>

                      </div>
                    <div class="column has-text-centered">
                        <span class="publication-links">
                            <span class="link-block"><a target="_blank" href="https://arxiv.org/pdf/2406.20083" class="external-link button is-normal is-rounded is-light"><span class="icon"><svg class="svg-inline--fa fa-file fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm160-14.1v6.1H256V0h6.1c6.4 0 12.5 2.5 17 7l97.9 98c4.5 4.5 7 10.6 7 16.9z"></path></svg></span><span>Paper</span></a></span>
                            <span class="link-block"><a target="_blank" href="https://arxiv.org/pdf/2312.02976.pdf" class="external-link button is-normal is-rounded is-light"><span class="icon"><i class="fas fa-file-pdf"></i></span><span>Supplement</span></a></span>
                            <span class="link-block"><a target="_blank" href="https://github.com/allenai/spoc-robot-training" class="external-link button is-normal is-rounded is-light"><span class="icon"><svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></span><span>Code (coming soon)</span></a></span>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<br>

<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero">
            <br>
            <h2 class="subtitle">
                FLaRe fine-tunes transformer BC policies pre-trained on large Robotics datasets with large-scale RL, achieving SoTA results across a set of manipulation and navigation tasks, in both simulation and real-world. 
                Furthermore, FLaRe shows exceptional adaptation capabilites towards mastering new task capacities, new embodiments, and new objectives efficiently.
                <!-- (see <a href="#numbers">Performance</a>). -->
            </h2>
            <img src="./static/images/teaser_crop-1.png"
                 class="interpolation-image"
                 width="800"
                 style="display: block; margin-left: auto; margin-right: auto"
                 alt="header-image."/>
            <br>
<!--             <img src="./static/images/model_v2-1.png"
                 class="interpolation-image"
                 alt="header-image."/>
            <br> -->
            <h2 class="subtitle">
                A key reason for the success of FLaRe is a set of simple but extremely important techniques to ensure that the RL fine-tuning can be carried out stably, including 1) fine-tuning from a multi-task robotics policy, 2) large-scale fine-tuning in simulation, 3) using an on-policy algorithm as opposed to off-policy methods, 4) utilizing smaller learning rate than when performing RL from scratch, 5) disabling the entropy bonus objective that can potentially distort the policy at the start of the training, and 6) separating the actor and the critic network, so that the critic update will not influence the policy prediction.
            </h2>
            <img src="./static/images/recipe_v2-1.png"
                 class="interpolation-image"
                 alt="header-image."/>
            <br>
            <h2 class="subtitle">
                
            </h2>
            <br>
            <br>
        </div>
    </div>
</section>

<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3 has-text-centered" id="Real-world examples">Real-world Qualitative Results</h2>
                <div class="content has-text-justified">
                    <p>
                        Here we present a number of real-world examples filmed in a real-world apartment <b>never seen</b> by the robot during training. All results are
                        collected using policies generated by <span class="dpoliformer">FLaRe</span> tine-tuning. In each video, we show the robot's RGB cameras input, as well as a 3rd person perspective. All videos are sped up by up to 20x for ease of viewing.
                    </p>

                    <img src="./static/images/real_world_layouts_v2-1.png" class="interpolation-image" alt="floorplan"/>
                    <h5 class="subtitle has-text-centered">
                        Floorplan of the real-world environment used for these qualitative examples.
                    </h5>
                </div>

                <br>
                <h2 class="title is-3  has-text-centered" id="ttsc">FLaRe for seen capabilities</h2>
                <p>
                    For tasks that are in the trainig data of the base model that FLaRe fine-tunes upon, FLaRe can effectively align the policies towards task completion, thereby achieving state-of-the-art performances. Below, we show examples of tasks from the CHORES benchmark.
                </p>
                <br>

                <h3 class="title is-4" id="find_apple_locobot">Find a Bed (from ObjectNav Task)</h3>
                <div class="content has-text-justified">
                    <p>
                        <span class="dpoliformer">FLaRe policy</span> finds a bed after exploring the unseen apartment with many rooms.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/find_bed.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/6mzRXp_Pvqs?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <h3 class="title is-4" id="find_humans_book_stretch">Grasp a Mug (from Pickup Task)</h3>
                <div class="content has-text-justified">
                    <p>
                        <span class="dpoliformer">FLaRe</span> successfully identifies and pick up a mug.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/grasp_mug.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/qomDB6CwEKY?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>


                <h3 class="title is-4" id="find_kitchen_stretch">Find and Hold an Apple (from Fetch Task)</h3>
                <div class="content has-text-justified">
                    <p>
                        <span class="dpoliformer">FLaRe</span> identifies and navigate to an apple, correctly position its base such that the apple is reacheable, and successfully pick the apple up.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/fetch_apple.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/blNhl7ph9h8?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <h3 class="title is-4">Visit all 6 Rooms in the House (from RoomVisit Task)</h3>
                <div class="content has-text-justified">
                    <p>
                        <span class="dpoliformer">FLaRe</span> explore the room extremely efficiently without requiring a map, and
                        successfully visit all 6 rooms, even though it has never seen this layout during training.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/roomvisit.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/HhgQBxrBQx0?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <br>
                <h2 class="title is-3 has-text-centered" id="ttsc">FLaRe for unseen capabilities</h2>
                <p>
                    Besides achieving SoTA performances on the aforementioned tasks, FLaRe can also be used to
                    efficiently adapt to new capabilities that are not presented in the training data of the base model.
                    These capabilities can be new tasks, new embodiments, new reasoning skills, or new objectives.
                    Below, we show examples of FLaRe adapting towards tasks and embodiments never seen during training.
                </p>

                <br>
                <h3 class="title is-4" id="find_multi_stretch">Locate the Chair Closest to the Refrigerator in the Kitchen (ObjNavRelAttr)</h3>
                <div class="content has-text-justified">
                    <p>
                        The ObjNavRelAttr task requires the robot to not just
                        find a specific type of object, but also reason about the object's attribute relative to other
                        objects. In this video, the FLaRe policy succesfully control the robot to find the chair in the
                        kitchen, while ignoring chairs that are in other rooms in the process.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/rel_ref_chair_frig.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/-fmA6xdzoG4?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <h3 class="title is-4" id="follow_toy_truck_stretch">Navigate to an Equipment for Watching Movies and Shows (ObjNavAfford)</h3>
                <div class="content has-text-justified">
                    <p>
                        The ObjNavAfford task requires the robot to have a high-level understanding of the affordance of
                        different objects. In this video, the FLaRe policy is able to correctly identify the TV as a target
                        object, and navigate to it, after a very long episode of exploring the environment.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/affordance.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/oJw1Y42h9jA?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <h3 class="title is-4" id="follow_person_stretch">Find the Living Room (RoomNav)</h3>
                <div class="content has-text-justified">
                    <p>
                        Unlike all the previous tasks, the RoomNav task requires the robot to understand concepts
                        related to room types, rather than just focusing on the objects. Here, the robot successfully
                        identifies the living room following the text instruction.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/living_room_nav.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/F2j6ryD41cM?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

                <h3 class="title is-4" id="follow_toy_truck_elanding">Find a Bed (LocoBot)</h3>
                <div class="content has-text-justified">
                    <p>
                        FLaRe allows us to repurpose the base model towards completely new embodiments. Here, we show
                        the FLaRe policy controlling a LoCoBot (as oppose to Stretch) to find a bed.
                    </p>
                </div>
                <div class="content has-text-centered">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="100%">-->
<!--                        <source src="static/videos/locobot.mp4" type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/AM-hoS5JKEk?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>

            </div>
        </div>
    </div>
</section>

<section class="section hero">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3 has-text-centered" id="Simulation examples">Behavior Analysis in Simulation and Realworld</h2>

                <p>
                    To better understand the decision-making process of FLaRe agent, we show multiple examples of
                    <span class="dpoliformer">FLaRe</span>'s behavior both in simulation and in the real world,
                    where we visualize both the camera
                    inputs as well as the probabilities the agent assigns to each of its available actions.
                </p>

                <h3 class="title is-4" style="padding-top: 1em" id="sim-2986_6_search_for_a_mug">Grasp Retry in Fetch Task (Take a Spray Bottle)</h3>
                <div class="content has-text-justified">
                    <p>
                        <span class="dpoliformer">FLaRe</span> learns close-loop behavior. When the first grasp failed,
                        the robot repositions itself and tries again, successfully grasping the spray bottle.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <video
                            controls
                            muted
                            preload
                            playsinline
                            width="100%">
                        <source src="./static/videos/unpaired/retry_fetch_spray_bottle.mp4" type="video/mp4">
                    </video>
                </div>

                <h3 class="title is-4"
                    id="sim-ArchitecTHOR-Test-00__proc5__global149__Laptop"
                    style="padding-top: 1em">Grasp the Houseplant / Apple</h3>
                <div class="content has-text-justified">
                    <p>
                        Even though the FLaRe agent does not have access to depth, it is able to learn good
                        pickup policy that is robust to different surface heights in the real world.
                    </p>
                </div>
                <div class="content has-text-centered"
                     style="display: flex; align-items: center; justify-content: center;">
<!--                    <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="50%"> &lt;!&ndash; Adjust the width as needed &ndash;&gt;-->
<!--                        <source src="./static/videos/grasp_plant.mp4"-->
<!--                                type="video/mp4">-->
<!--                    </video>-->
<!--                                        <video-->
<!--                            controls-->
<!--                            muted-->
<!--                            preload-->
<!--                            playsinline-->
<!--                            width="50%"> &lt;!&ndash; Adjust the width as needed &ndash;&gt;-->
<!--                        <source src="./static/videos/grasp_apple.mp4"-->
<!--                                type="video/mp4">-->
<!--                    </video>-->
                    <iframe
                        src="https://www.youtube.com/embed/hsqxQB7zbkA?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 50%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                    <iframe
                        src="https://www.youtube.com/embed/WlbNm1ay63g?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 50%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>


                <h3 class="title is-4"
                    id="sim-51__proc16__global519__Television"
                    style="padding-top: 1em">RoomVisit in RoboThor (Distinct Scene)</h3>
                <div class="content has-text-justified">
                    <p>
                        We found the FLaRe policy to be quite robust across distinct realworld environments, thanks to the large number
                        of houses it has seen during training in simulation. In this video, we
                        show the robot conducting room exploration in RoboThor.
                    </p>
                </div>
                <div class="content has-text-centered"
                     style="display: flex; align-items: center; justify-content: center;">
                    <video
                            controls
                            muted
                            preload
                            playsinline
                            width="100%"> <!-- Adjust the width as needed -->
                        <source src="./static/videos/robothor_3_room.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <h3 class="title is-4"
                    id="sim-FloorPlan326__proc21__global366__GarbageCan"
                    style="padding-top: 1em">Locate a Produce that is best for Eating Fresh as Snacks (ObjNavAfford)</h3>
                <div class="content has-text-justified">
                    <p>
                        Another affordance task completion in the realworld, where the robot correctly identifies the
                        right produce (i.e. Apple) and call the DONE action.
                    </p>
                </div>
                <div class="content has-text-centered"
                     style="display: flex; align-items: center; justify-content: center;">
                    <video
                            controls
                            muted
                            preload
                            playsinline
                            width="100%">
                        <source src="./static/videos/unpaired/good_affordnav.mp4"
                                type="video/mp4">
                    </video>
                </div>


                <h3 class="title is-4"
                    style="padding-top: 1em"> Long-horizon Reasoning and Memory (RoomVisit)</h3>
                <div class="content has-text-justified">
                    <p>
                        The Transformer architecture enables long-horizon memory and reasoning. In this clip, we show
                        the robot completing the room visit task in an extremely challenging house layout with 7 rooms.
                        Notice how the agent calls sub-done as soon as it enters every unvisited room, demonstrating its
                         exceptional memory capacity, and spatial reasoning abilities.

                    </p>
                </div>
                <div class="content has-text-centered"
                     style="display: flex; align-items: center; justify-content: center;">
                    <video
                            controls
                            muted
                            preload
                            playsinline
                            width="70%"> <!-- Adjust the width as needed -->
                        <source src="./static/videos/room_visit_sim.mp4"
                                type="video/mp4">
                    </video>
                    <img src="./static/videos/room_visit_pic.png"
                         alt="ArchitecTHOR Image" width="30%"> <!-- Adjust the width as needed -->
                </div>

            </div>
        </div>

    </div>
</section>

<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3 has-text-centered" id="Real-world examples">Failure Mode Analysis</h2>

                <h3 class="title is-4">Find and Grasp an Apple (Fetch)</h3>
                <div class="content has-text-justified">
                    <p>
                        One typical failure mode in the real world is grasp failure. In the future, we plan to improve this by
                        1) equip the robot with depth sensing capabilities, and 2) improve the physics realisticity
                        of our simulator.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <iframe
                        src="https://www.youtube.com/embed/GmkSCTRpU30?controls=1&mute=1&playsinline=1&modestbranding=1"
                        style="width: 100%;aspect-ratio: 16/9;"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>
                <p> Another failure mode is object mismatch between simulation and real world. For example, we found that
                    the FLaRe policy had trouble recognizing the vases in the real world (as shown by the clip). Upon investigation, we realize that
                    a primary cause for this issue is that the vases in simulation looks quite different from the realworld
                    vases that we tested upon. We expect further diversification of objects in simulation to alleviate this issue.</p>
                <div class="content has-text-centered">
                    <video
                            controls
                            muted
                            preload
                            playsinline
                            width="100%"> <!-- Adjust the width as needed -->
                        <source src="./static/videos/vase_failure.mp4"
                                type="video/mp4">
                    </video>
                </div>

            </div>
        </div>

    </div>
</section>


<!--<section class="section hero">-->
<!--    <div class="container is-max-desktop">-->
<!--        <div class="columns is-centered">-->
<!--            <div class="column" style="width: 100%;">-->
<!--                <h2 class="title">BibTeX</h2>-->
<!--                <div class="grid-container-one-no-box">-->
<!--            <pre><code>@article{-->
<!--        poliformer2024,-->
<!--        author    = {Kuo-Hao Zeng, Zichen Zhang, Kiana Ehsani, Rose Hendrix, Jordi Salvador, Alvaro Herrasti, Ross Girshick, Aniruddha Kembhavi, Luca Weihs},-->
<!--        title     = {PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful Navigators},-->
<!--        journal   = {arXiv},-->
<!--        year      = {2024},-->
<!--        eprint    = {2406.20083},-->
<!--}</code></pre>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

<!--</section>-->

<footer class="footer" style="background-color: #f5f5f5">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
<!--                    <p>-->
<!--                        This website based on the <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA-->
<!--                        4.0</a> licensed-->
<!--                        <a rel="template" href="https://github.com/nerfies/nerfies.github.io">Nerfies website</a>.-->
<!--                    </p>-->
                    <h2 class="title is-4 has-text-centered">Please check out our paper and code for more detail on FLaRe!</h2>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
